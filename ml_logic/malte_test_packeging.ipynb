{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ data received\n",
      "✅ data cleaned\n",
      "✅ randomly removed 4373664 non-fraudulent rows from the data frame.\n"
     ]
    }
   ],
   "source": [
    "from data import * \n",
    "df = get_data_local()\n",
    "df = clean_data(df)\n",
    "df = data_reduction(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ data One-Hot-Encoded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Malte/.pyenv/versions/3.10.6/envs/aml_detector/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "/Users/Malte/.pyenv/versions/3.10.6/envs/aml_detector/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "/Users/Malte/.pyenv/versions/3.10.6/envs/aml_detector/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from preprocessor import preprocess_features\n",
    "\n",
    "df = preprocess_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Number of nodes: 77414\n",
      "✅ Number of edges: 51770\n"
     ]
    }
   ],
   "source": [
    "from edges_nodes import create_nodes_edges\n",
    "\n",
    "G = create_nodes_edges(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ x created\n",
      "✅ target created\n",
      "✅ test_x created\n",
      "✅ test_target created\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from model import FraudGNN\n",
    "from model import model_data\n",
    "from model import train_test\n",
    "\n",
    "x, target = model_data(G, df)\n",
    "x, test_x, target, test_target = train_test(x, target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 12013392.0\n",
      "Epoch: 20, Loss: 346025.25\n",
      "Epoch: 40, Loss: 656085.5\n",
      "Epoch: 60, Loss: 1644322.875\n",
      "Epoch: 80, Loss: 573492.9375\n",
      "Epoch: 100, Loss: 313183.4375\n",
      "Epoch: 120, Loss: 21301.798828125\n",
      "Epoch: 140, Loss: 334518.46875\n",
      "Epoch: 160, Loss: 2048.93212890625\n",
      "Epoch: 180, Loss: 293497.40625\n",
      "Epoch: 200, Loss: 510855.9375\n"
     ]
    }
   ],
   "source": [
    "from train import train_model\n",
    "\n",
    "optimizer, model, target = train_model(FraudGNN, x, target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model evaluated\n",
      "accuracy: 0.8926984667778015\n",
      "precision: 0.05094905197620392\n",
      "recall: 0.24056604504585266\n",
      "f1: 0.08408903330564499\n",
      "auroc: 0.5734480619430542\n",
      "0.8926984667778015\n"
     ]
    }
   ],
   "source": [
    "from evaluate import predict\n",
    "from evaluate import evaluate_model\n",
    "\n",
    "binary_predictions = predict(model,test_x)\n",
    "\n",
    "result = evaluate_model(test_target, binary_predictions)\n",
    "\n",
    "print (result[0].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aml_detector",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
